{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter Name\n",
      "Sree\n"
     ]
    }
   ],
   "source": [
    "name = input(\"Enter Name\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists('data/Class/%s'%name):\n",
    "    os.makedirs('data/Class/%s'%name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to detect face using OpenCV\n",
    "def detect_face(img):\n",
    "    #convert the test image to gray image as opencv face detector expects gray images\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "    #load OpenCV face detector, I am using haarcascade_frontalface_default\n",
    "    \n",
    "    face_cascade = cv2.CascadeClassifier('data/haarcascade_frontalface_default.xml')\n",
    "    #let's detect multiscale (some images may be closer to camera than others) images\n",
    "    #result is a list of faces\n",
    "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5);\n",
    "    \n",
    "    #if no faces are detected then return original img\n",
    "    if (len(faces) == 0):\n",
    "        return None, None\n",
    "    \n",
    "    #under the assumption that there will be only one face,\n",
    "    #extract the face area\n",
    "    (x, y, w, h) = faces[0]\n",
    "    \n",
    "    #return only the face part of the image\n",
    "    return img[y:y+w, x:x+h], faces[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectangle(img, rect):\n",
    "    (x, y, w, h) = rect\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 255, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 99  59  42]\n",
      "  [100  60  43]\n",
      "  [102  59  43]\n",
      "  ...\n",
      "  [ 79  41   6]\n",
      "  [ 79  44  13]\n",
      "  [ 83  48  18]]\n",
      "\n",
      " [[ 98  59  45]\n",
      "  [ 98  59  45]\n",
      "  [ 97  57  43]\n",
      "  ...\n",
      "  [ 79  41   6]\n",
      "  [ 78  42  12]\n",
      "  [ 86  51  20]]\n",
      "\n",
      " [[ 96  60  45]\n",
      "  [ 92  56  42]\n",
      "  [ 94  56  42]\n",
      "  ...\n",
      "  [ 80  43   6]\n",
      "  [ 80  46  12]\n",
      "  [ 82  48  15]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 26   0   0]\n",
      "  [ 26   0   0]\n",
      "  [ 24   0   0]\n",
      "  ...\n",
      "  [ 18   0   0]\n",
      "  [ 22   0   0]\n",
      "  [ 22   0   0]]\n",
      "\n",
      " [[ 26   0   0]\n",
      "  [ 26   0   0]\n",
      "  [ 24   0   0]\n",
      "  ...\n",
      "  [ 18   0   0]\n",
      "  [ 20   0   0]\n",
      "  [ 20   0   0]]\n",
      "\n",
      " [[ 24   0   0]\n",
      "  [ 24   0   0]\n",
      "  [ 24   0   0]\n",
      "  ...\n",
      "  [ 18   0   0]\n",
      "  [ 18   0   0]\n",
      "  [ 18   0   0]]]\n",
      "<class 'numpy.ndarray'>\n",
      "True\n",
      "[[[ 99  63  48]\n",
      "  [ 98  62  47]\n",
      "  [ 95  59  42]\n",
      "  ...\n",
      "  [ 82  48   0]\n",
      "  [ 84  56  10]\n",
      "  [ 87  59  14]]\n",
      "\n",
      " [[ 97  62  45]\n",
      "  [ 97  62  45]\n",
      "  [100  67  45]\n",
      "  ...\n",
      "  [ 86  51   7]\n",
      "  [ 84  57  16]\n",
      "  [ 86  59  18]]\n",
      "\n",
      " [[ 97  62  45]\n",
      "  [ 99  64  47]\n",
      "  [103  68  49]\n",
      "  ...\n",
      "  [ 87  50  13]\n",
      "  [ 86  55  19]\n",
      "  [ 88  57  21]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 28   0   0]\n",
      "  [ 28   0   0]\n",
      "  [ 30   0   0]\n",
      "  ...\n",
      "  [ 26   0   0]\n",
      "  [ 26   0   0]\n",
      "  [ 26   0   0]]\n",
      "\n",
      " [[ 28   0   0]\n",
      "  [ 28   0   0]\n",
      "  [ 30   0   0]\n",
      "  ...\n",
      "  [ 28   0   0]\n",
      "  [ 26   0   0]\n",
      "  [ 26   0   0]]\n",
      "\n",
      " [[ 30   0   0]\n",
      "  [ 30   0   0]\n",
      "  [ 30   0   0]\n",
      "  ...\n",
      "  [ 32   0   0]\n",
      "  [ 28   0   0]\n",
      "  [ 28   0   0]]]\n",
      "<class 'numpy.ndarray'>\n",
      "True\n",
      "[[[115  80  56]\n",
      "  [117  82  58]\n",
      "  [115  79  58]\n",
      "  ...\n",
      "  [ 96  60  25]\n",
      "  [ 90  66  35]\n",
      "  [ 94  70  40]]\n",
      "\n",
      " [[111  75  51]\n",
      "  [107  72  48]\n",
      "  [112  76  53]\n",
      "  ...\n",
      "  [ 96  61  23]\n",
      "  [ 92  66  34]\n",
      "  [ 94  68  36]]\n",
      "\n",
      " [[112  76  53]\n",
      "  [109  74  50]\n",
      "  [112  76  53]\n",
      "  ...\n",
      "  [105  66  25]\n",
      "  [ 95  69  32]\n",
      "  [ 96  70  33]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 35   3   0]\n",
      "  [ 32   1   0]\n",
      "  [ 32   0   0]\n",
      "  ...\n",
      "  [ 39   2   0]\n",
      "  [ 38   0   0]\n",
      "  [ 38   0   0]]\n",
      "\n",
      " [[ 33   1   0]\n",
      "  [ 32   0   0]\n",
      "  [ 32   0   0]\n",
      "  ...\n",
      "  [ 40  10   0]\n",
      "  [ 39   4   0]\n",
      "  [ 38   3   0]]\n",
      "\n",
      " [[ 31   0   0]\n",
      "  [ 30   0   0]\n",
      "  [ 30   0   0]\n",
      "  ...\n",
      "  [ 43  16   0]\n",
      "  [ 42  13   0]\n",
      "  [ 41  12   0]]]\n",
      "<class 'numpy.ndarray'>\n",
      "True\n",
      "[[[111  85  60]\n",
      "  [111  85  60]\n",
      "  [112  87  59]\n",
      "  ...\n",
      "  [108  67  35]\n",
      "  [103  65  37]\n",
      "  [104  66  38]]\n",
      "\n",
      " [[108  82  59]\n",
      "  [107  81  58]\n",
      "  [111  85  60]\n",
      "  ...\n",
      "  [101  63  28]\n",
      "  [101  63  33]\n",
      "  [101  63  33]]\n",
      "\n",
      " [[108  83  57]\n",
      "  [105  79  54]\n",
      "  [105  79  54]\n",
      "  ...\n",
      "  [101  64  27]\n",
      "  [101  64  31]\n",
      "  [102  65  32]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 20   3   0]\n",
      "  [ 20   3   0]\n",
      "  [ 30   0   0]\n",
      "  ...\n",
      "  [ 56  19   7]\n",
      "  [ 63  27  12]\n",
      "  [ 64  28  14]]\n",
      "\n",
      " [[ 28   6   0]\n",
      "  [ 24   3   0]\n",
      "  [ 32   0   0]\n",
      "  ...\n",
      "  [ 58  22   8]\n",
      "  [ 66  29  12]\n",
      "  [ 69  31  14]]\n",
      "\n",
      " [[ 28   6   0]\n",
      "  [ 24   3   0]\n",
      "  [ 30   0   0]\n",
      "  ...\n",
      "  [ 55  22   7]\n",
      "  [ 62  27  10]\n",
      "  [ 68  33  15]]]\n",
      "<class 'numpy.ndarray'>\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "counter = 1\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "    print(frame)\n",
    "    print(type(frame))\n",
    "    print(ret)\n",
    "\n",
    "    face,rect = detect_face(frame)\n",
    "    if rect is not None:\n",
    "        draw_rectangle(frame,rect)\n",
    "        cv2.imwrite('data/Class/%s/%s.jpg'%(name,counter),face)\n",
    "        counter+=1\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "# When everything is done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_map(x):\n",
    "    if x=='Sachin':\n",
    "        return 0\n",
    "    if x=='Sree':\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_training_data(data_folder_path):\n",
    "    \n",
    "    #------STEP-1--------\n",
    "    #get the directories (one directory for each subject) in data folder\n",
    "    dirs = os.listdir(data_folder_path)\n",
    "    \n",
    "    #list to hold all subject faces\n",
    "    faces = []\n",
    "    #list to hold labels for all subjects\n",
    "    labels = []\n",
    "    \n",
    "    #let's go through each directory and read images within it\n",
    "    for dir_name in dirs:\n",
    "        \n",
    "            \n",
    "        #------STEP-2--------\n",
    "        #extract label number of subject from dir_name\n",
    "        label = dir_name\n",
    "        \n",
    "        #build path of directory containin images for current subject subject\n",
    "        #sample subject_dir_path = \"data/DB/sachin\"\n",
    "        subject_dir_path = data_folder_path + \"/\" + dir_name\n",
    "        \n",
    "        #get the images names that are inside the given subject directory\n",
    "        subject_images_names = os.listdir(subject_dir_path)\n",
    "        \n",
    "        #------STEP-3--------\n",
    "        #go through each image name, read image, \n",
    "        #detect face and add face to list of faces\n",
    "        for image_name in subject_images_names:\n",
    "            \n",
    "            #ignore system files like .DS_Store\n",
    "            if image_name.startswith(\".\"):\n",
    "                continue;\n",
    "            \n",
    "            #build image path\n",
    "            #sample image path = training-data/s1/1.pgm\n",
    "            image_path = subject_dir_path + \"/\" + image_name\n",
    "\n",
    "            #read image\n",
    "            image = cv2.imread(image_path)\n",
    "            \n",
    "            #display an image window to show the image \n",
    "            cv2.imshow(\"Training on image...\", image)\n",
    "            cv2.waitKey(100)\n",
    "\n",
    "            \n",
    "            \n",
    "            #------STEP-4--------\n",
    "            #for the purpose of this tutorial\n",
    "            #we will ignore faces that are not detected\n",
    "            if image is not None:\n",
    "                #add face to list of faces\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "                faces.append(image)\n",
    "                #add label for this face\n",
    "                labels.append(name_map(label))\n",
    "            \n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)\n",
    "    cv2.destroyAllWindows()\n",
    "    return faces, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data...\n",
      "Data prepared\n",
      "Total faces:  29\n",
      "Total labels:  29\n"
     ]
    }
   ],
   "source": [
    "print(\"Preparing data...\")\n",
    "faces, labels = prepare_training_data(\"data/Class\")\n",
    "print(\"Data prepared\")\n",
    "\n",
    "#print total faces and labels\n",
    "print(\"Total faces: \", len(faces))\n",
    "print(\"Total labels: \", len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_recognizer = cv2.face.LBPHFaceRecognizer_create()\n",
    "\n",
    "face_recognizer.train(faces, np.array(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_rectangle(img, rect):\n",
    "    (x, y, w, h) = rect\n",
    "    cv2.rectangle(img, (x, y), (x+w, y+h), (255, 255, 255), 2)\n",
    "\n",
    "def draw_text(img, text, x, y):\n",
    "    cv2.putText(img, text, (x, y), cv2.FONT_HERSHEY_PLAIN, 1.5, (255, 255, 255), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_name(x):\n",
    "    if x==0:\n",
    "        return 'Sachin'\n",
    "    if x==1:\n",
    "        return 'Sree'\n",
    "    if x == 2:\n",
    "        return 'messi'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_img):\n",
    "    #make a copy of the image as we don't want to chang original image\n",
    "    img = test_img.copy()\n",
    "    #detect face from the image\n",
    "    face, rect = detect_face(img)\n",
    "    print(rect)\n",
    "\n",
    "    #predict the image using our face recognizer \n",
    "    try:\n",
    "        label= face_recognizer.predict(face)\n",
    "        print(label)\n",
    "        #get name of respective label returned by face recognizer\n",
    "        #label_text = subjects[label[0]]\n",
    "        label_text = get_name(label[0])\n",
    "        #draw a rectangle around face detected\n",
    "        draw_rectangle(img, rect)\n",
    "        #draw name of predicted person\n",
    "        draw_text(img, label_text, rect[0], rect[1]-5)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[271  83 271 271]\n",
      "[274  87 264 264]\n",
      "[264  79 282 282]\n",
      "[269  87 268 268]\n",
      "[268  83 276 276]\n",
      "[287 102 241 241]\n"
     ]
    }
   ],
   "source": [
    "video_capture = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    # Capture frame-by-frame\n",
    "    ret, frame = video_capture.read()\n",
    "\n",
    "    predicted_img1 = predict(frame)\n",
    "\n",
    "    # Display the resulting frame\n",
    "    cv2.imshow('Video', predicted_img1)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == 27:\n",
    "        break\n",
    "# When everything is done, release the capture\n",
    "video_capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
